{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ImpLogReg import ImpLogReg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import itertools as it\n",
    "from tqdm import tqdm\n",
    "import pba\n",
    "\n",
    "import matplotlib\n",
    "font = {'size'   : 14}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "from LRF import *\n",
    "\n",
    "def intervalise(val,eps,method='u',b=0,bounds = None):\n",
    "    \n",
    "    if method == 'u':\n",
    "        m = np.random.uniform(val-eps,val+eps)\n",
    "    elif method == 't':\n",
    "        m = np.random.triangular(val-eps,val-b*eps,val+eps)\n",
    "    \n",
    "    if bounds is not None:\n",
    "        if m-eps < bounds[0]:\n",
    "            return pba.I(bounds[0],m+eps)\n",
    "        elif m+eps >bounds[1]:\n",
    "            return pba.I(m-eps,bounds[1])\n",
    "        \n",
    "    return pba.I(m-eps,m+eps)\n",
    "\n",
    "\n",
    "def deintervalise(data, binary_cols):\n",
    "    n_data = data.copy()\n",
    "    for c in data.columns:\n",
    "        if c in binary_cols:\n",
    "            continue\n",
    "        for i in data.index:\n",
    "            if data.loc[i,c].__class__.__name__ == 'Interval':\n",
    "                n_data.loc[i,c] = data.loc[i,c].left + np.random.rand()*data.loc[i,c].width()\n",
    "            \n",
    "    return n_data\n",
    "\n",
    "### Import data\n",
    "data = pd.read_table('burn1000.txt',index_col = 'ID')\n",
    "\n",
    "results = data['DEATH']\n",
    "train_data = data[[c for c in data.columns if c not in ['DEATH','FACILITY']]]\n",
    "\n",
    "UQdata = train_data.copy()\n",
    "\n",
    "# Split the data into test/train factors and result and generate uncertain points\n",
    "random.seed(1) # for reproducability\n",
    "\n",
    "## Select some data to be intervalised\n",
    "index_list = [i for i in data.index]\n",
    "\n",
    "ininj_index = random.sample(index_list, k = 20) \n",
    "uq_data_index = random.sample(index_list,k = 10)\n",
    "\n",
    "u_index = ininj_index\n",
    "\n",
    "UQdata = pd.DataFrame({\n",
    "    **{\n",
    "        \"INH_INJ\": [pba.I(0,1) if i in ininj_index else train_data.loc[i,\"INH_INJ\"] for i in index_list],\n",
    "        \"AGE\": [pba.I(80,90) if train_data.loc[i,'AGE'] > 80 else train_data.loc[i,'AGE'] for i in index_list]\n",
    "        },\n",
    "    **{c: train_data[c] for c in train_data.columns if c not in (\"INH_INJ\",'AGE')},\n",
    "    }, index = data.index, dtype = 'O').reindex(columns = train_data.columns)\n",
    "UQdata.to_csv('burn_uq.csv')\n",
    "# uq_results = pd.Series([int(results.loc[i]) if i not in uq_data_index else pba.I(0,1) for i in results.index], index = results.index, dtype='O')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Fit logistic regression model on full dataset\n",
    "base = LogisticRegression(max_iter=1000)\n",
    "base.fit(train_data.to_numpy(),results.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Fit models with none UQ data data\n",
    "nuq_data =  deintervalise(UQdata.loc[[i for i in data.index if i not in [*u_index,*uq_data_index]]],[\"INH_INJ\"])\n",
    "nuq_results = results.loc[[i for i in data.index if i not in [*u_index,*uq_data_index]]]\n",
    "nuq = LogisticRegression(max_iter=1000)\n",
    "nuq.fit(nuq_data.to_numpy(),nuq_results.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Fit UQ models\n",
    "# uq_models = uc_int_logistic_regression(UQdata,results.drop(uq_data_index),results.loc[uq_data_index],binary_cols = [\"INH_INJ\"],uq_data_index=uq_data_index)\n",
    "ilr = ImpLogReg(max_iter = 1000, uncertain_class=0, uncertain_data=True)\n",
    "ilr.fit(UQdata, results, catagorical=[\"INH_INJ\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Get confusion matrix\n",
    "# Classify test data\n",
    "base_predict = base.predict(train_data)\n",
    "\n",
    "# CLASSIFY NO_UQ MODEL DATA \n",
    "nuq_predict = nuq.predict(train_data)\n",
    "\n",
    "# CLASSIFY UQ MODEL \n",
    "ilr_predict = ilr.predict(train_data)\n",
    "\n",
    "with open('runinfo/burn1000_cm.out','w') as f:\n",
    "    print('TRUE MODEL',file = f)\n",
    "    a,b,c,d = generate_confusion_matrix(results,base_predict)\n",
    "    print('TP=%i\\tFP=%i\\nFN=%i\\tTN=%i' %(a,b,c,d),file = f)\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    print('Sensitivity = %.3f' %(a/(a+c)),file = f)\n",
    "    print('Specificity = %.3f' %(d/(b+d)),file = f)\n",
    "\n",
    "    print('DISCARDED DATA MODEL',file = f)\n",
    "    aa,bb,cc,dd = generate_confusion_matrix(results,nuq_predict)\n",
    "    try:\n",
    "        ss = 1/(1+cc/aa)\n",
    "    except:\n",
    "        ss = None\n",
    "    try:    \n",
    "        tt = 1/(1+bb/dd)\n",
    "    except:\n",
    "        tt = None\n",
    "    print('TP=%s\\tFP=%s\\nFN=%s\\tTN=%s' %(aa,bb,cc,dd),file = f)\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    print('Sensitivity = %.3f' %(ss),file = f)\n",
    "    print('Specificity = %.3f' %(tt),file = f)\n",
    "    \n",
    "    print('UQ MODEL',file = f)\n",
    "    \n",
    "    aaai,bbbi,ccci,dddi = generate_confusion_matrix(results,ilr_predict,throw = False)\n",
    "    try:\n",
    "        sssi = aaai/(a+c)\n",
    "    except:\n",
    "        sssi = None\n",
    "    try:    \n",
    "        ttti = dddi/(b+d)\n",
    "    except:\n",
    "        ttti = None\n",
    "\n",
    "    print('TP=[%i,%i]\\tFP=[%i,%i]\\nFN=[%i,%i]\\tTN=[%i,%i]' %(*aaai,*bbbi,*ccci,*dddi),file = f)\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    print('Sensitivity = [%.3f,%.3f]\\nSpecificity = [%.3f,%.3f]' %(*sssi,*ttti),file = f)\n",
    "\n",
    "    \n",
    "    aaa,bbb,ccc,ddd,eee,fff = generate_confusion_matrix(results,ilr_predict,throw = True)\n",
    "    try:\n",
    "        sss = 1/(1+ccc/aaa)\n",
    "    except:\n",
    "        sss = None\n",
    "    try:    \n",
    "        ttt = 1/(1+bbb/ddd)\n",
    "    except:\n",
    "        ttt = None\n",
    "        \n",
    "    print('TP=%i\\tFP=%i\\nFN=%i\\tTN=%i\\nNP(+)=%i\\tNP(-)=%i' %(aaa,bbb,ccc,ddd,eee,fff),file = f)\n",
    "\n",
    "    # Calculate sensitivity and specificity\n",
    "    print('Sensitivity = %.3f' %(sss),file = f)\n",
    "    print('Specificity = %.3f' %(ttt),file = f)\n",
    "    print('sigma = %.3f' %(eee/(aaa+ccc+eee)),file = f)\n",
    "    print('tau = %.3f' %(fff/(bbb+ddd+fff)),file = f)\n",
    "   \n",
    "\n",
    "### Descriminatory Performance Plots\n",
    "# s,fpr,probabilities = ROC(model = base, data = train_data, results = results)\n",
    "\n",
    "nuq_s,nuq_fpr,nuq_probabilities = ROC(model = nuq, data = train_data, results = results)\n",
    "s_t, fpr_t, Sigma, Tau = incert_ROC(ilr, train_data, results)\n",
    "\n",
    "s_i, fpr_i,ilr_probabilities = ROC(ilr, train_data, results)\n",
    "s_l, fpr_l,ilr_l_probabilities = ROC(ilr, train_data, results, func = lambda x: x.left)\n",
    "s_r, fpr_r,ilr_r_probabilities = ROC(ilr, train_data, results, func = lambda x: x.right)\n",
    "\n",
    "\n",
    "densfig,axdens = plt.subplots(nrows = 2, sharex= True)\n",
    "\n",
    "for i,(u,nuqp,r) in enumerate(zip(ilr_probabilities,nuq_probabilities,results.to_list())):\n",
    "    yd = np.random.uniform(-0.1,0.1)\n",
    "    if r:\n",
    "\n",
    "        axdens[0].scatter(nuqp,0.21+yd,color = '#DC143C',marker = 'o',alpha = 0.5)\n",
    "        axdens[0].plot([*u],[yd-0.21,yd-0.21],color = '#4169E1',alpha = 0.3)\n",
    "        axdens[0].scatter([*u],[yd-0.21,yd-0.21],color = '#4169E1',marker = '|')\n",
    "    else:\n",
    "\n",
    "        axdens[1].scatter(nuqp,0.21+yd,color = '#DC143C',marker = 'o',alpha = 0.5)\n",
    "        axdens[1].plot([*u],[yd-0.21,yd-0.21],color = '#4169E1',alpha = 0.3)\n",
    "        axdens[1].scatter([*u],[yd-0.21,yd-0.21],color = '#4169E1',marker = '|')\n",
    "        \n",
    "        \n",
    "axdens[0].set(ylabel = 'Outcome = 1',yticks = [])\n",
    "axdens[1].set(xlabel = '$\\pi(x)$',ylabel = 'Outcome = 0',yticks = [],xlim  = (0, 1))\n",
    "\n",
    "densfig.tight_layout()\n",
    "\n",
    "rocfig,axroc = plt.subplots(1,1)\n",
    "axroc.plot([0,1],[0,1],'k:')\n",
    "axroc.set(xlabel = '$fpr$',ylabel='$s$')\n",
    "# axroc.plot(fpr,s,'k',label = 'Base')\n",
    "axroc.plot(nuq_fpr,nuq_s,color='#DC143C',label='Ignored Uncertainty')\n",
    "axroc.plot(fpr_t,s_t,'#4169E1',label='Imprecise (No Predict.)')\n",
    "axroc.plot(fpr_l,s_l,'#FF8827',label='Lower Bound')\n",
    "axroc.plot(fpr_r,s_r,'#007e00',label='Upper Bound')\n",
    "\n",
    "axroc.legend()\n",
    "rocfig.savefig('figs/burn1000_ROC.png',dpi = 600)\n",
    "# rocfig.savefig('../paper/figs/burn1000_ROC.png',dpi = 600)\n",
    "densfig.savefig('figs/burn1000_dens.png',dpi =600)\n",
    "# densfig.savefig('../paper/figs/burn1000_dens.png',dpi =600)\n",
    "\n",
    "\n",
    "with open('runinfo/burn1000_auc.out','w') as f:\n",
    "    print('MIDPOINTS: %.4F' %auc(nuq_s,nuq_fpr),file = f)\n",
    "    print('NP: %.4f' %auc(s_t,fpr_t), file = f)\n",
    "    print('LB: %.4f' %auc(s_l,fpr_l), file = f)\n",
    "    print('UB: %.4f' %auc(s_r,fpr_r), file = f)\n",
    "\n",
    "    # print('INTERVALS: [%.3f,%.3f]' %(auc_int_min,auc_int_max), file = f)\n",
    "    \n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d',elev = 45,azim = -45,proj_type = 'ortho')\n",
    "ax.set_xlabel('$fpr$')\n",
    "ax.set_ylabel('$s$')\n",
    "# ax.set_zlabel('$1-\\sigma,1-\\\\tau$')\n",
    "ax.plot(fpr_t,s_t,'#4169E1',alpha = 0.5)\n",
    "ax.plot3D(fpr_t,s_t,Sigma,'#FF8C00',label = '$\\\\sigma$')\n",
    "ax.plot3D(fpr_t,s_t,Tau,'#008000',label = '$\\\\tau$')\n",
    "# ax.plot3D(fpr,s,Nu,'k',label = '$1-\\\\nu$')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "# plt.savefig('figs/burn1000_ROC3D.png',dpi = 600)\n",
    "# plt.savefig('../paper/figs/burn1000_ROC3D.png',dpi = 600)\n",
    "plt.clf()\n",
    "\n",
    "plt.xlabel('$fpr$/$s$')\n",
    "plt.ylabel('$\\\\sigma$/$\\\\tau$')\n",
    "plt.plot(s_t,Sigma,'#FF8C00',label = '$\\\\sigma$ v $s$')\n",
    "plt.plot(fpr_t,Tau,'#008000',label = '$\\\\tau$ v $fpr$')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# plt.savefig('figs/burn1000_ST.png',dpi = 600)\n",
    "# plt.savefig('../paper/figs/burn1000_ST.png',dpi = 600)\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "\n",
    "### Hosmer-Lemeshow\n",
    "hl_b, pval_b = hosmer_lemeshow_test(base,train_data,results,g = 10)\n",
    "\n",
    "hl_nuq, pval_nuq = hosmer_lemeshow_test(nuq,train_data,results,g = 10)\n",
    "#\n",
    "hl_uq, pval_uq = UQ_hosmer_lemeshow_test(ilr,train_data,results,g = 10)\n",
    "\n",
    "with open('runinfo/burn1000_HL.out','w') as f:\n",
    "    print('base\\nhl = %.3f, p = %.3f' %(hl_b,pval_b),file = f)\n",
    "    print('no UQ\\nhl = %.3f, p = %.3f' %(hl_nuq,pval_nuq),file = f) \n",
    "\n",
    "    print('UQ\\nhl = [%.3f,%.3f], p = [%.3f,%.3f]' %(*hl_uq,*pval_uq),file = f) "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
